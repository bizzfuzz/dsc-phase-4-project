{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. DATA PREPARATION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ian/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "#warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>Google's Zeiger, a physician never reported po...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9091</th>\n",
       "      <td>Some Verizon iPhone customers complained their...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9092</th>\n",
       "      <td>Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9093 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  \\\n",
       "0     .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1     @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2     @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3     @sxsw I hope this year's festival isn't as cra...   \n",
       "4     @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "...                                                 ...   \n",
       "9088                      Ipad everywhere. #SXSW {link}   \n",
       "9089  Wave, buzz... RT @mention We interrupt your re...   \n",
       "9090  Google's Zeiger, a physician never reported po...   \n",
       "9091  Some Verizon iPhone customers complained their...   \n",
       "9092  Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...   \n",
       "\n",
       "     emotion_in_tweet_is_directed_at  \\\n",
       "0                             iPhone   \n",
       "1                 iPad or iPhone App   \n",
       "2                               iPad   \n",
       "3                 iPad or iPhone App   \n",
       "4                             Google   \n",
       "...                              ...   \n",
       "9088                            iPad   \n",
       "9089                             NaN   \n",
       "9090                             NaN   \n",
       "9091                             NaN   \n",
       "9092                             NaN   \n",
       "\n",
       "     is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                      Negative emotion  \n",
       "1                                      Positive emotion  \n",
       "2                                      Positive emotion  \n",
       "3                                      Negative emotion  \n",
       "4                                      Positive emotion  \n",
       "...                                                 ...  \n",
       "9088                                   Positive emotion  \n",
       "9089                 No emotion toward brand or product  \n",
       "9090                 No emotion toward brand or product  \n",
       "9091                 No emotion toward brand or product  \n",
       "9092                 No emotion toward brand or product  \n",
       "\n",
       "[9093 rows x 3 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"judge-1377884607_tweet_product_company.csv\",encoding='ISO-8859-1')#since the default encoding used by pandas(utf-8) could not decode the byte in the csv filr\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9093 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column                                              Non-Null Count  Dtype \n",
      "---  ------                                              --------------  ----- \n",
      " 0   tweet_text                                          9092 non-null   object\n",
      " 1   emotion_in_tweet_is_directed_at                     3291 non-null   object\n",
      " 2   is_there_an_emotion_directed_at_a_brand_or_product  9093 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 213.2+ KB\n",
      "None\n",
      "---------------------------------------\n",
      "DataFrame Shape: (9093, 3)\n",
      "None\n",
      "---------------------------------------\n",
      "DataFrame Description:\n",
      "                                               tweet_text  \\\n",
      "count                                                9092   \n",
      "unique                                               9065   \n",
      "top     RT @mention Marissa Mayer: Google Will Connect...   \n",
      "freq                                                    5   \n",
      "\n",
      "       emotion_in_tweet_is_directed_at  \\\n",
      "count                             3291   \n",
      "unique                               9   \n",
      "top                               iPad   \n",
      "freq                               946   \n",
      "\n",
      "       is_there_an_emotion_directed_at_a_brand_or_product  \n",
      "count                                                9093  \n",
      "unique                                                  4  \n",
      "top                    No emotion toward brand or product  \n",
      "freq                                                 5389  \n",
      "None\n",
      "---------------------------------------\n",
      "Null Values in DataFrame:\n",
      "tweet_text                                               1\n",
      "emotion_in_tweet_is_directed_at                       5802\n",
      "is_there_an_emotion_directed_at_a_brand_or_product       0\n",
      "dtype: int64\n",
      "None\n",
      "---------------------------------------\n",
      "Number of Duplicate Rows: 22\n",
      "Duplicate Rows:\n",
      "                                             tweet_text  \\\n",
      "468      Before It Even Begins, Apple Wins #SXSW {link}   \n",
      "776   Google to Launch Major New Social Network Call...   \n",
      "2232  Marissa Mayer: Google Will Connect the Digital...   \n",
      "2559  Counting down the days to #sxsw plus strong Ca...   \n",
      "3950  Really enjoying the changes in Gowalla 3.0 for...   \n",
      "3962  #SXSW is just starting, #CTIA is around the co...   \n",
      "4897  Oh. My. God. The #SXSW app for iPad is pure, u...   \n",
      "5338  RT @mention ÷¼ GO BEYOND BORDERS! ÷_ {link} ...   \n",
      "5341  RT @mention ÷¼ Happy Woman's Day! Make love, ...   \n",
      "5881  RT @mention Google to Launch Major New Social ...   \n",
      "5882  RT @mention Google to Launch Major New Social ...   \n",
      "5883  RT @mention Google to Launch Major New Social ...   \n",
      "5884  RT @mention Google to Launch Major New Social ...   \n",
      "5885  RT @mention Google to Launch Major New Social ...   \n",
      "6296  RT @mention Marissa Mayer: Google Will Connect...   \n",
      "6297  RT @mention Marissa Mayer: Google Will Connect...   \n",
      "6298  RT @mention Marissa Mayer: Google Will Connect...   \n",
      "6299  RT @mention Marissa Mayer: Google Will Connect...   \n",
      "6300  RT @mention Marissa Mayer: Google Will Connect...   \n",
      "6546  RT @mention RT @mention Google to Launch Major...   \n",
      "8483  I just noticed DST is coming this weekend. How...   \n",
      "8747  Need to buy an iPad2 while I'm in Austin at #s...   \n",
      "\n",
      "     emotion_in_tweet_is_directed_at  \\\n",
      "468                            Apple   \n",
      "776                              NaN   \n",
      "2232                             NaN   \n",
      "2559                           Apple   \n",
      "3950                     Android App   \n",
      "3962                         Android   \n",
      "4897              iPad or iPhone App   \n",
      "5338                             NaN   \n",
      "5341                             NaN   \n",
      "5881                             NaN   \n",
      "5882                             NaN   \n",
      "5883                             NaN   \n",
      "5884                             NaN   \n",
      "5885                             NaN   \n",
      "6296                          Google   \n",
      "6297                             NaN   \n",
      "6298                          Google   \n",
      "6299                             NaN   \n",
      "6300                             NaN   \n",
      "6546                             NaN   \n",
      "8483                          iPhone   \n",
      "8747                            iPad   \n",
      "\n",
      "     is_there_an_emotion_directed_at_a_brand_or_product  \n",
      "468                                    Positive emotion  \n",
      "776                  No emotion toward brand or product  \n",
      "2232                 No emotion toward brand or product  \n",
      "2559                                   Positive emotion  \n",
      "3950                                   Positive emotion  \n",
      "3962                                   Positive emotion  \n",
      "4897                                   Positive emotion  \n",
      "5338                 No emotion toward brand or product  \n",
      "5341                 No emotion toward brand or product  \n",
      "5881                 No emotion toward brand or product  \n",
      "5882                 No emotion toward brand or product  \n",
      "5883                 No emotion toward brand or product  \n",
      "5884                 No emotion toward brand or product  \n",
      "5885                 No emotion toward brand or product  \n",
      "6296                                   Positive emotion  \n",
      "6297                 No emotion toward brand or product  \n",
      "6298                                   Positive emotion  \n",
      "6299                 No emotion toward brand or product  \n",
      "6300                 No emotion toward brand or product  \n",
      "6546                 No emotion toward brand or product  \n",
      "8483                                   Negative emotion  \n",
      "8747                                   Positive emotion  \n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Checking the Dataset status\n",
    "class DataFrameChecker:\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def check_info(self):\n",
    "        print(\"DataFrame Info:\")\n",
    "        self.dataframe.info()\n",
    "\n",
    "    def check_shape(self):\n",
    "        print(f\"DataFrame Shape: {self.dataframe.shape}\")\n",
    "\n",
    "    def check_describe(self):\n",
    "        print(\"DataFrame Description:\")\n",
    "        print(self.dataframe.describe())\n",
    "    def check_nulls(self):\n",
    "        print(\"Null Values in DataFrame:\")\n",
    "        print(self.dataframe.isnull().sum())\n",
    "\n",
    "    def check_duplicates(self):\n",
    "        duplicate_rows = self.dataframe[self.dataframe.duplicated()]\n",
    "        print(f\"Number of Duplicate Rows: {duplicate_rows.shape[0]}\")\n",
    "        if duplicate_rows.shape[0] > 0:\n",
    "            print(\"Duplicate Rows:\")\n",
    "            print(duplicate_rows)\n",
    "\n",
    "\n",
    "    # Create an instance of DataFrameChecker\n",
    "checker = DataFrameChecker(df)\n",
    "\n",
    "    # Use the methods\n",
    "print(checker.check_info())\n",
    "print(\"---------------------------------------\")\n",
    "print(checker.check_shape())\n",
    "print(\"---------------------------------------\")\n",
    "print(checker.check_describe())\n",
    "print(\"---------------------------------------\")\n",
    "print(checker.check_nulls())\n",
    "print(\"---------------------------------------\")\n",
    "print(checker.check_duplicates())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Data Cleaning \"emotion_in_tweet_is_directed_at\" Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion_in_tweet_is_directed_at\n",
       "iPad                               946\n",
       "Apple                              661\n",
       "iPad or iPhone App                 470\n",
       "Google                             430\n",
       "iPhone                             297\n",
       "Other Google product or service    293\n",
       "Android App                         81\n",
       "Android                             78\n",
       "Other Apple product or service      35\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"emotion_in_tweet_is_directed_at\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorizing the brands to either Apple or Google products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brand\n",
      "Apple     2409\n",
      "Google     882\n",
      "Name: count, dtype: int64\n",
      "---------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9093 entries, 0 to 9092\n",
      "Data columns (total 4 columns):\n",
      " #   Column                                              Non-Null Count  Dtype \n",
      "---  ------                                              --------------  ----- \n",
      " 0   tweet_text                                          9092 non-null   object\n",
      " 1   emotion_in_tweet_is_directed_at                     3291 non-null   object\n",
      " 2   is_there_an_emotion_directed_at_a_brand_or_product  9093 non-null   object\n",
      " 3   brand                                               3291 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 284.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "product_category={\n",
    "    \"iPhone\":\"Apple\", \n",
    "    \"iPad\":\"Apple\",\n",
    "    \"iPad or iPhone App\":\"Apple\", \n",
    "    \"Other Apple product or service\": \"Apple\",\n",
    "    \"Android\":\"Google\", \n",
    "    \"Android App\":\"Google\", \n",
    "    \"Other Google product or service\":\"Google\"\n",
    "}\n",
    "df[\"brand\"]=df[\"emotion_in_tweet_is_directed_at\"].replace(product_category)\n",
    "\n",
    "               \n",
    "print(df[\"brand\"].value_counts())\n",
    "print(\"---------------------------------------\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with missing values in the brand column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@teachntech00 New iPad Apps For #SpeechTherapy...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Holler Gram for iPad on the iTunes App Store -...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Attn: All  #SXSW frineds, @mention Register fo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Anyone at  #sxsw want to sell their old iPad?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Currently 150 people in line at the &amp;quot;Pop ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Only iPad 2 available at #sxsw is the 64GB wif...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>÷¼ We love 2 entertain youÛ_Please donÛªt b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>Less than 2 hours until we announce the detail...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>(The iPad 2 queue at #sxsw of course</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            tweet_text  \\\n",
       "5    @teachntech00 New iPad Apps For #SpeechTherapy...   \n",
       "6                                                  NaN   \n",
       "16   Holler Gram for iPad on the iTunes App Store -...   \n",
       "32   Attn: All  #SXSW frineds, @mention Register fo...   \n",
       "33       Anyone at  #sxsw want to sell their old iPad?   \n",
       "..                                                 ...   \n",
       "186  Currently 150 people in line at the &quot;Pop ...   \n",
       "187  Only iPad 2 available at #sxsw is the 64GB wif...   \n",
       "188  ÷¼ We love 2 entertain youÛ_Please donÛªt b...   \n",
       "189  Less than 2 hours until we announce the detail...   \n",
       "191               (The iPad 2 queue at #sxsw of course   \n",
       "\n",
       "    emotion_in_tweet_is_directed_at  \\\n",
       "5                               NaN   \n",
       "6                               NaN   \n",
       "16                              NaN   \n",
       "32                              NaN   \n",
       "33                              NaN   \n",
       "..                              ...   \n",
       "186                             NaN   \n",
       "187                             NaN   \n",
       "188                             NaN   \n",
       "189                             NaN   \n",
       "191                             NaN   \n",
       "\n",
       "    is_there_an_emotion_directed_at_a_brand_or_product brand  \n",
       "5                   No emotion toward brand or product   NaN  \n",
       "6                   No emotion toward brand or product   NaN  \n",
       "16                  No emotion toward brand or product   NaN  \n",
       "32                  No emotion toward brand or product   NaN  \n",
       "33                  No emotion toward brand or product   NaN  \n",
       "..                                                 ...   ...  \n",
       "186                 No emotion toward brand or product   NaN  \n",
       "187                 No emotion toward brand or product   NaN  \n",
       "188                 No emotion toward brand or product   NaN  \n",
       "189                 No emotion toward brand or product   NaN  \n",
       "191                 No emotion toward brand or product   NaN  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df=df[df[\"brand\"].isna()]\n",
    "filtered_df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping the 'emotion_in_tweet_is_directed_at' column since the 'brand' column is a replacement of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9093 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column                                              Non-Null Count  Dtype \n",
      "---  ------                                              --------------  ----- \n",
      " 0   tweet_text                                          9092 non-null   object\n",
      " 1   is_there_an_emotion_directed_at_a_brand_or_product  9093 non-null   object\n",
      " 2   brand                                               3291 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 213.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.drop(columns=['emotion_in_tweet_is_directed_at'], inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the filtered_df there are words in the tweet_text column that can help identify the brand.\n",
    "For example, if the tweet_text contains the word \"iPhone,\" it's likely an Apple brand. Similarly, if the tweet_text contains the word \"Android,\" it's likely a Google brand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeywordBrandAssigner:\n",
    "    def __init__(self, keyword_to_brand):\n",
    "        self.keyword_to_brand = keyword_to_brand  # Mapping from keywords to brands\n",
    "\n",
    "    def assign_brands(self, df):\n",
    "        for index, row in df.iterrows():\n",
    "            text = row['tweet_text']\n",
    "            if pd.isna(row['brand']) and isinstance(text, str):\n",
    "                text_lower = text.lower()\n",
    "                for keyword, brand in self.keyword_to_brand.items():\n",
    "                    if keyword in text_lower:\n",
    "                        df.at[index, 'brand'] = brand\n",
    "                        break\n",
    "        # Fill any remaining NaN values with 'Unknown'\n",
    "        df['brand'] = df['brand'].fillna('Unknown')\n",
    "\n",
    "# Example usage\n",
    "keyword_to_brand = {\n",
    "    'google': 'Google',\n",
    "    'apple': 'Apple',\n",
    "    'ipad': 'Apple',\n",
    "    'itunes': 'Apple',\n",
    "    'android': 'Google',\n",
    "    'iphone': 'Apple'\n",
    "}\n",
    "\n",
    "assigner = KeywordBrandAssigner(keyword_to_brand)\n",
    "assigner.assign_brands(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KeywordBrandAssigner class maps specific keywords to their corresponding brands (\"Apple\" or \"Google\") based on the keyword_to_brand dictionary and assigns these brands to the 'brand' column of the DataFrame when a keyword is found in the tweet text. It ensures that any missing or unmatched values in the 'brand' column are filled with \"Unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "brand\n",
       "Apple      5440\n",
       "Google     2946\n",
       "Unknown     707\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reloading the dataset\n",
    "df[\"brand\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropped the rows with unknown values since i'm focussed with tweets having information about either Google or Apple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "brand\n",
       "Apple     5440\n",
       "Google    2946\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropping records with unknown values in the brand column\n",
    "df.drop(df[df[\"brand\"] == \"Unknown\"].index, inplace=True)\n",
    "df[\"brand\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8386 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column                                              Non-Null Count  Dtype \n",
      "---  ------                                              --------------  ----- \n",
      " 0   tweet_text                                          8386 non-null   object\n",
      " 1   is_there_an_emotion_directed_at_a_brand_or_product  8386 non-null   object\n",
      " 2   brand                                               8386 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 262.1+ KB\n"
     ]
    }
   ],
   "source": [
    "#Reloading the data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking and Dropping of Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    8366\n",
      "True       20\n",
      "Name: count, dtype: int64\n",
      "---------------------------------------\n",
      "(8366, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df.duplicated().value_counts())\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(\"---------------------------------------\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    8366\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Data Cleaning \"is there an emotion directed at a brand or product\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_there_an_emotion_directed_at_a_brand_or_product\n",
       "No emotion toward brand or product    4688\n",
       "Positive emotion                      2960\n",
       "Negative emotion                       568\n",
       "I can't tell                           150\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"is_there_an_emotion_directed_at_a_brand_or_product\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4 classifiers(no emotion,positive,negative and I can't tell)\n",
    "\n",
    "I need to consolidate the existing categorical emotions into three distinct classes. Specifically, I will categorize \"Positive emotion\" as the positive class, the \"No emotion toward brand or product,\" as neutral and  \"Negative emotion,\" as negative. The \"I can't tell\" records will be treated as missing data and dropped.  This transformation will simplify the classification task and enable the development of an emotion classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_there_an_emotion_directed_at_a_brand_or_product\n",
      "Neutral         0.560363\n",
      "Positive        0.353813\n",
      "Non-Positive    0.067894\n",
      "Unknown         0.017930\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "Emotions={\n",
    "    \"No emotion toward brand or product\":\"Neutral\",\n",
    "    \"Positive emotion\":\"Positive\",\n",
    "    \"Negative emotion\":\"Non-Positive\",\n",
    "    \"I can't tell\":\"Unknown\"\n",
    "}\n",
    "df.loc[:,\"is_there_an_emotion_directed_at_a_brand_or_product\"] = df[\"is_there_an_emotion_directed_at_a_brand_or_product\"].map(Emotions)\n",
    "               \n",
    "print(df[\"is_there_an_emotion_directed_at_a_brand_or_product\"].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping the unknowns in the 'is_there_an_emotion_directed_at_a_brand feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_there_an_emotion_directed_at_a_brand_or_product\n",
       "Neutral         4688\n",
       "Positive        2960\n",
       "Non-Positive     568\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(df[df[\"is_there_an_emotion_directed_at_a_brand_or_product\"] == \"Unknown\"].index, inplace=True)\n",
    "df[\"is_there_an_emotion_directed_at_a_brand_or_product\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPLAROTORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing\n",
    "\n",
    "The initial step in preparing the dataset for summarization involves breaking each tweet (currently stored as a text string in the overall table) into individual tokens, separated by commas, and then repopulating each row in the dataframe as a list of tokens. The tokenizer uses a regular expression pattern to split words by non-letter characters while preserving apostrophes within words where relevant. \n",
    "\n",
    "Areas of focus  for the preprocessing phase:\n",
    "\n",
    "i. Tokenizing the tweet texts using 'Tweet Tokenizer' that handles hastages('#') and mentions ('@').\n",
    "\n",
    "ii. Removing basic Stop Words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>Google</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text           emotion   brand\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...  Negative emotion   Apple\n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  Positive emotion   Apple\n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...  Positive emotion   Apple\n",
       "3  @sxsw I hope this year's festival isn't as cra...  Negative emotion   Apple\n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...  Positive emotion  Google"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rename columns for easier usage\n",
    "df.rename(columns={'tweet_text':'text'}, inplace=True)\n",
    "df.rename(columns={'is_there_an_emotion_directed_at_a_brand_or_product':'emotion'}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/dev/anaconda/envs/dev/lib/python3.8/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/dev/anaconda/envs/dev/lib/python3.8/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/dev/anaconda/envs/dev/lib/python3.8/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m filtered_tokens\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Apply the function to remove stopwords and special characters from the 'text' column\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(remove_stopwords_and_special_chars)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Initializing Tokenizer\u001b[39;00m\n\u001b[1;32m     15\u001b[0m tknzr \u001b[38;5;241m=\u001b[39m TweetTokenizer(strip_handles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, preserve_case \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, )\n",
      "File \u001b[0;32m~/dev/anaconda/envs/dev/lib/python3.8/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/dev/anaconda/envs/dev/lib/python3.8/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'text'"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.probability import FreqDist\n",
    "from string import punctuation\n",
    "\n",
    "stop_words = set(stopwords.words('english') + list(punctuation))\n",
    "#function to remove stopwords and special characters\n",
    "def remove_stopwords_and_special_chars(tokens):\n",
    "    filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "    return filtered_tokens\n",
    "# Apply the function to remove stopwords and special characters from the 'text' column\n",
    "df['text'] = df['text'].apply(remove_stopwords_and_special_chars)\n",
    "\n",
    "\n",
    "# Initializing Tokenizer\n",
    "tknzr = TweetTokenizer(strip_handles = True, preserve_case = False, )\n",
    "df['text'] = df['text'].apply(tknzr.tokenize)\n",
    "\n",
    "# Function for getting the 20 most common words in the tweets\n",
    "def get_most_common_words(df, column_name):\n",
    "    tokens = df[column_name].sum()\n",
    "    fdist = FreqDist(tokens)\n",
    "    return fdist.most_common(20)\n",
    "\n",
    "# applying the function\n",
    "top_words = get_most_common_words(df, 'text')\n",
    "print(top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bee\\AppData\\Local\\Temp\\ipykernel_11452\\531373548.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sentiment'] = df_probs['sentiment']\n"
     ]
    }
   ],
   "source": [
    "df['sentiment'] = df_probs['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting the tweet_text column for further analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your re...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>Google's Zeiger, a physician never reported po...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9091</th>\n",
       "      <td>Some Verizon iPhone customers complained their...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9092</th>\n",
       "      <td>Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8366 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  sentiment\n",
       "0     .@wesley83 I have a 3G iPhone. After 3 hrs twe...        0.0\n",
       "1     @jessedee Know about @fludapp ? Awesome iPad/i...        1.0\n",
       "2     @swonderlin Can not wait for #iPad 2 also. The...        0.0\n",
       "3     @sxsw I hope this year's festival isn't as cra...        1.0\n",
       "4     @sxtxstate great stuff on Fri #SXSW: Marissa M...        1.0\n",
       "...                                                 ...        ...\n",
       "9088                      Ipad everywhere. #SXSW {link}        0.0\n",
       "9089  Wave, buzz... RT @mention We interrupt your re...        0.0\n",
       "9090  Google's Zeiger, a physician never reported po...        0.0\n",
       "9091  Some Verizon iPhone customers complained their...        0.0\n",
       "9092  Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...        0.0\n",
       "\n",
       "[8366 rows x 2 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df[['tweet_text', 'sentiment']]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bee\\AppData\\Local\\Temp\\ipykernel_11452\\3637978030.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['sentiment'] = data['sentiment'].replace(4,1)\n"
     ]
    }
   ],
   "source": [
    "data['sentiment'] = data['sentiment'].replace(4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separating positive and negative tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pos = data[data['sentiment'] == 1]\n",
    "data_neg = data[data['sentiment'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taking one-fourth of the data so that it can be computationally lightweight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pos = data_pos.iloc[:int(20000)]\n",
    "data_neg = data_neg.iloc[:int(20000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining positive and negative tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([data_pos, data_neg])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making tweet text in lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9088                        ipad everywhere. #sxsw {link}\n",
       "9089    wave, buzz... rt @mention we interrupt your re...\n",
       "9090    google's zeiger, a physician never reported po...\n",
       "9091    some verizon iphone customers complained their...\n",
       "9092    ï¡ïàü_êîò£áââ_£â_ûârt @...\n",
       "Name: tweet_text, dtype: object"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['tweet_text']=dataset['tweet_text'].str.lower()\n",
    "dataset['tweet_text'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Managing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwordlist = ['a', 'about', 'above', 'after', 'again', 'ain', 'all', 'am', 'an',\n",
    "             'and','any','are', 'as', 'at', 'be', 'because', 'been', 'before',\n",
    "             'being', 'below', 'between','both', 'by', 'can', 'd', 'did', 'do',\n",
    "             'does', 'doing', 'down', 'during', 'each','few', 'for', 'from',\n",
    "             'further', 'had', 'has', 'have', 'having', 'he', 'her', 'here',\n",
    "             'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in',\n",
    "             'into','is', 'it', 'its', 'itself', 'just', 'll', 'm', 'ma',\n",
    "             'me', 'more', 'most','my', 'myself', 'now', 'o', 'of', 'on', 'once',\n",
    "             'only', 'or', 'other', 'our', 'ours','ourselves', 'out', 'own', 're','s', 'same', 'she', \"shes\", 'should', \"shouldve\",'so', 'some', 'such',\n",
    "             't', 'than', 'that', \"thatll\", 'the', 'their', 'theirs', 'them',\n",
    "             'themselves', 'then', 'there', 'these', 'they', 'this', 'those',\n",
    "             'through', 'to', 'too','under', 'until', 'up', 've', 'very', 'was',\n",
    "             'we', 'were', 'what', 'when', 'where','which','while', 'who', 'whom',\n",
    "             'why', 'will', 'with', 'won', 'y', 'you', 'youd','youll', 'youre',\n",
    "             'youve', 'your', 'yours', 'yourself', 'yourselves', '#sxsw', 'sxsw', 'sxswi', '#sxswi', 'rt', 'ipad', 'google', 'apple', 'iphone', 'amp',\n",
    "             'android', 'sxswi', 'link', '#apple',\n",
    "             '#google', ''...'', '\\x89', '#ipad2',\n",
    "             '0','1','2','3','4','5','6','7','8','9',\n",
    "             '#iphone', '#android', 'store', 'austin', '#ipad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
